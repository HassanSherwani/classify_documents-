{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0EB-00JFbTu"
   },
   "source": [
    "# Advanced ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgD89GH8FbTv"
   },
   "source": [
    "# 1)- Import key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPdEp39wFbTw"
   },
   "outputs": [],
   "source": [
    "# support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRdpb4goFbT0"
   },
   "outputs": [],
   "source": [
    "import re    # for regular expressions \n",
    "import nltk  # for text manipulation \n",
    "import string \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string \n",
    "\n",
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWdqIo5eFbT3"
   },
   "outputs": [],
   "source": [
    "#models and evaluation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.classify.scikitlearn import SklearnClassifier # notice its from ntlk not sklearn\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Evaluation packages\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mcY1ltBZF3bY",
    "outputId": "c42e903e-d6ff-4b6e-cdb1-74444ef1e54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: version_information in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install version_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "yRhRcERtFbT7",
    "outputId": "4d5e1243-d4eb-4201-efe3-7e0e5874d7a8"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.9 64bit [GCC 8.4.0]"
        },
        {
         "module": "IPython",
         "version": "5.5.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.19.112+ x86_64 with Ubuntu 18.04 bionic"
        },
        {
         "module": "pandas",
         "version": "1.0.5"
        },
        {
         "module": "numpy",
         "version": "1.18.5"
        },
        {
         "module": "nltk",
         "version": "3.2.5"
        },
        {
         "module": "seaborn",
         "version": "0.10.1"
        },
        {
         "module": "matplotlib",
         "version": "3.2.2"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.9 64bit [GCC 8.4.0]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.19.112+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>1.0.5</td></tr><tr><td>numpy</td><td>1.18.5</td></tr><tr><td>nltk</td><td>3.2.5</td></tr><tr><td>seaborn</td><td>0.10.1</td></tr><tr><td>matplotlib</td><td>3.2.2</td></tr><tr><td colspan='2'>Fri Sep 25 13:40:47 2020 UTC</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.9 64bit [GCC 8.4.0] \\\\ \\hline\n",
       "IPython & 5.5.0 \\\\ \\hline\n",
       "OS & Linux 4.19.112+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\n",
       "pandas & 1.0.5 \\\\ \\hline\n",
       "numpy & 1.18.5 \\\\ \\hline\n",
       "nltk & 3.2.5 \\\\ \\hline\n",
       "seaborn & 0.10.1 \\\\ \\hline\n",
       "matplotlib & 3.2.2 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Sep 25 13:40:47 2020 UTC} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.9 64bit [GCC 8.4.0]\n",
       "IPython 5.5.0\n",
       "OS Linux 4.19.112+ x86_64 with Ubuntu 18.04 bionic\n",
       "pandas 1.0.5\n",
       "numpy 1.18.5\n",
       "nltk 3.2.5\n",
       "seaborn 0.10.1\n",
       "matplotlib 3.2.2\n",
       "Fri Sep 25 13:40:47 2020 UTC"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install version_information\n",
    "%reload_ext version_information\n",
    "%version_information pandas,numpy, nltk, seaborn, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1BbV39JbF5bl",
    "outputId": "7f1ee843-3376-4a2b-d48e-41c14607e581"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing GPU on colab\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJdgcSFTFbT-"
   },
   "source": [
    "# 2)- Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z5gG3WTYFbUA",
    "outputId": "bfc20a73-b802-4018-d126-3bf0cb01e40e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train_data_clean.csv')\n",
    "#data=data.rename(columns={'Unnamed: 0':'random_columns'}) # a trick to tackle random index values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "bz9eBJgLFbUG",
    "outputId": "2dccf5c2-b884-40d3-838b-a682680a704a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top 5 Reasons Why 'Divergent' Star Kate Winsle...</td>\n",
       "      <td>e</td>\n",
       "      <td>top 5 reason diverg star kate winslet deserv s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vessyl Bottle Tracks Your Drink And Its Health...</td>\n",
       "      <td>t</td>\n",
       "      <td>vessyl bottl track drink health benefitsgadget...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  ...                                              clean\n",
       "0  Top 5 Reasons Why 'Divergent' Star Kate Winsle...  ...  top 5 reason diverg star kate winslet deserv s...\n",
       "1  Vessyl Bottle Tracks Your Drink And Its Health...  ...  vessyl bottl track drink health benefitsgadget...\n",
       "\n",
       "[2 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "4xFzLpbSGJcL",
    "outputId": "bc638808-c855-42b1-d5d9-7172546b9b10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news        0\n",
       "category    0\n",
       "clean       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vOYa_SMGwxG"
   },
   "outputs": [],
   "source": [
    "#loading test feature and label data saved from previous notebooks\n",
    "feature_test=pd.read_csv('test_data.csv')\n",
    "label_test=pd.read_csv('test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EetJbAEyG0ve",
    "outputId": "782fa534-9b71-4b8e-cb9a-77b707db42dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84484, 2)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "print(feature_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKt6gOTkFbUc"
   },
   "source": [
    "# 3)- Vectorization\n",
    "\n",
    "- bag of words\n",
    "- tf-idf\n",
    "- doc2vec\n",
    "- word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ShFfXjBmFbUl",
    "outputId": "f3707449-17b0-49bb-f077-cafa36784d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "features=data['clean']\n",
    "labels=data['category']\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VQNqyhaFbUp"
   },
   "source": [
    "### 3.1).Bag of Words\n",
    "\n",
    "Bag-of-Words is a method to represent text into numerical features.\n",
    "\n",
    "Let us understand this using a simple example. Suppose we have only 2 document\n",
    "\n",
    "- D1: He is a lazy boy. She is also lazy.\n",
    "\n",
    "- D2: Smith is a lazy person.\n",
    "\n",
    "The list created would consist of all the unique tokens in the corpus C.\n",
    "\n",
    "= [‘He’,’She’,’lazy’,’boy’,’Smith’,’person’]\n",
    "\n",
    "Here, D=2, N=6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XZzIES8cFbUq",
    "outputId": "a2c95893-8d8e-4c38-ac45-83caa814c5fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import gensim\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(features)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3l-p5QNMe1K"
   },
   "source": [
    "#### 3.1.a. Transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "cHBkiisSMdwH",
    "outputId": "acb7426e-feaf-40ac-d782-9262cab27c37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153245</td>\n",
       "      <td>iPhone 6 Release Date Pushed Back Due to Issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308611</td>\n",
       "      <td>Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title\n",
       "0      153245  iPhone 6 Release Date Pushed Back Due to Issue...\n",
       "1      308611  Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl..."
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X15rD6fIMd7c"
   },
   "outputs": [],
   "source": [
    "bow_test = bow_vectorizer.transform(feature_test[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lxMDMLx7MeHs",
    "outputId": "f84eb8f9-7cb9-4a6b-e56d-5b6ade79c69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(84484, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(bow.shape)\n",
    "print(bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iG1YMKlTFbUt"
   },
   "source": [
    "### 3.2)-TF-IDF\n",
    "\n",
    "This is another method which is based on the frequency method but it is different to the bag-of-words approach in the sense that it takes into account not just the occurrence of a word in a single document (or tweet) but in the entire corpus.\n",
    "\n",
    "TF-IDF works by penalising the common words by assigning them lower weights while giving importance to words which are rare in the entire corpus but appear in good numbers in few documents.\n",
    "\n",
    "Let’s have a look at the important terms related to TF-IDF:\n",
    "\n",
    "- TF = (Number of times term t appears in a document)/(Number of terms in the document)\n",
    "\n",
    "- IDF = log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n",
    "\n",
    "- TF-IDF = TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LmBmDmJwFbUu",
    "outputId": "c4f735eb-c980-4d47-c99e-c2dbb85935e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(features)\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kv4t_vJdMzbz"
   },
   "source": [
    "#### 3.2.a. Transform Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtrSZpXkM3bv"
   },
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(feature_test[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lPomwNbtM3fp",
    "outputId": "467a4245-4ee5-4fe2-d60b-34c64e70e69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(84484, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.shape)\n",
    "print(tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uugYJWZrFbUy"
   },
   "source": [
    "### 3.3)- Doc2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnItz5KrFbUy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IYkbNZTHgv8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fK2gRZ9PFbU1"
   },
   "outputs": [],
   "source": [
    "tokenized_text = data['clean'].apply(lambda x: x.split()) # tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLbq7ImhFbU5"
   },
   "outputs": [],
   "source": [
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(twt.index, twt):\n",
    "        output.append(TaggedDocument(s, [\"clean_\" + str(i)]))\n",
    "    return output\n",
    "labeled_text = add_label(tokenized_text) # label all the news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbQjox6DFbU8"
   },
   "source": [
    "##### 3.3.a.Train doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XQwLPzOFbU9"
   },
   "outputs": [],
   "source": [
    "model_d2v = gensim.models.Doc2Vec(dm=1,dm_mean=1,vector_size=200,window=5,negative=7,min_count=5,workers=3,alpha=0.1,seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RJydoaBGFbU_",
    "outputId": "0aa3bacf-9187-44ce-d093-7b8afa6997f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 1565856.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model_d2v.build_vocab([i for i in tqdm(labeled_text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0yLmMlpFbVB"
   },
   "source": [
    "##### 3.3.b.Preparing doc2vec Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XF4puIMZFbVC",
    "outputId": "45cccc7f-cce9-4de0-cc72-5e9273db605f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docvec_arrays = np.zeros((len(tokenized_text), 200))\n",
    "for i in range(len(data)):\n",
    "    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1,200))\n",
    "\n",
    "    \n",
    "docvec_df = pd.DataFrame(docvec_arrays)\n",
    "docvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "LQQ0LflTFbVE",
    "outputId": "6de386c9-912a-489d-e4ed-4c0c0c515838"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.001438</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>-0.002418</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.001502</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.002053</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>-0.002106</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.002324</td>\n",
       "      <td>-0.002378</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.001385</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>-0.001983</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.001959</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>-0.002029</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>-0.002291</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>-0.000762</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.002202</td>\n",
       "      <td>-0.001380</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>-0.000378</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>-0.001951</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.002424</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>-0.001414</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001507</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-0.002038</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>-0.000675</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>-0.001908</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.002208</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.002186</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-0.001396</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.001756</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>-0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>-0.001224</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>-0.001980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.001873</td>\n",
       "      <td>-0.001280</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.001868</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>-0.002051</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.001928</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>-0.002397</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.002108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001080</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.001405</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.002068</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.002499</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>-0.001256</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>-0.002065</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.002027</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.000956</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.001609</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.002416</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    ...       197       198       199\n",
       "0  0.002366  0.000339  0.001979  ... -0.001185  0.001691 -0.000495\n",
       "1  0.002128  0.001104 -0.000378  ... -0.001520  0.001158  0.002369\n",
       "2  0.000065 -0.000689  0.001343  ...  0.000314  0.001539 -0.001834\n",
       "3  0.000201 -0.000361  0.001026  ... -0.001592 -0.001095 -0.002108\n",
       "4 -0.001080  0.001557 -0.000543  ... -0.002416  0.002157  0.000595\n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docvec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsU7YQSnKq1I"
   },
   "source": [
    "#### 3.3.3.transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "kja4-fxMLAKf",
    "outputId": "3b16cf54-85ce-4b7b-eb61-923d672f89e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153245</td>\n",
       "      <td>iPhone 6 Release Date Pushed Back Due to Issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308611</td>\n",
       "      <td>Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title\n",
       "0      153245  iPhone 6 Release Date Pushed Back Due to Issue...\n",
       "1      308611  Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl..."
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6b0uJzWKuEI"
   },
   "outputs": [],
   "source": [
    "tokenized_text_test = feature_test['title'].apply(lambda x: x.split()) # tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ac5GB3hdKuHX"
   },
   "outputs": [],
   "source": [
    "labeled_text_test = add_label(tokenized_text_test) # label all the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NH6BlSjPKuM5"
   },
   "outputs": [],
   "source": [
    "docvec_arrays_test = np.zeros((len(tokenized_text_test), 200))\n",
    "for i in range(len(data)):\n",
    "    docvec_arrays_test[i,:] = model_d2v.docvecs[i].reshape((1,200))\n",
    "\n",
    "    \n",
    "docvec_df_test = pd.DataFrame(docvec_arrays_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7vvmUKHdKuVH",
    "outputId": "196e3621-d9ef-4bf7-f87c-08bcc0831b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(84484, 200)\n"
     ]
    }
   ],
   "source": [
    "print(docvec_df.shape) # training\n",
    "print(docvec_df_test.shape) # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMSFv9OGME8x"
   },
   "source": [
    "Notice I have only transformed test set and didn't train. So only my train set learns about vocab of corpus. My test model has only been transformed and learnt nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_tp2_ErFbVG"
   },
   "source": [
    "### 3.4.Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IqpPfRHnFbVG",
    "outputId": "4eaa7f29-0f02-4b01-bf01-ea9b8841ba2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329944, 1633380)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = data['clean'].apply(lambda x: x.split()) # tokenizing\n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_text,\n",
    "            size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2,\n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling i.e class with other types\n",
    "            workers= 2, # no.of cores\n",
    "            seed = 34) \n",
    "\n",
    "model_w2v.train(tokenized_text, total_examples= len(data['clean']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "KtntKOSTFbVJ",
    "outputId": "9a277efb-f5fb-4f76-c2b4-7385f56dd758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02183259, -0.4366339 ,  0.06510326,  0.72783786,  0.24485947,\n",
       "        0.33850783,  0.3416138 , -0.50301486,  0.29840896,  0.12920056,\n",
       "        0.09041848, -0.50774693,  0.34069255, -0.43587837, -0.4792716 ,\n",
       "        0.1502633 , -0.16197556,  0.3467329 , -0.26033154, -0.22837308,\n",
       "       -0.2995486 ,  0.00264726,  0.32378572, -0.42868358,  0.03162241,\n",
       "       -0.03673098, -0.34075603,  0.09162065, -0.15626894, -0.29774606,\n",
       "        0.15991998, -0.05255641,  0.45747536, -0.31701863, -0.01571083,\n",
       "       -0.13146812,  0.42375457, -0.31759384, -0.12677263,  0.25047785,\n",
       "        0.44083124,  0.34026486,  0.02389309,  0.14316827,  0.26641372,\n",
       "       -0.01980806, -0.14764051, -0.00484273,  0.03565803,  0.2957805 ,\n",
       "       -0.00778876, -0.40688795, -0.72026014,  0.0653047 ,  0.13537495,\n",
       "        0.16425957, -0.48244882, -0.5117245 ,  0.24898359, -0.30187702,\n",
       "        0.29498556,  0.3112112 ,  0.10090353,  0.5491042 , -0.03915667,\n",
       "        0.08010899, -0.2108901 , -0.051441  ,  0.5548677 ,  0.18952012,\n",
       "        0.11895771, -0.01379667, -0.4140535 , -0.12756105, -0.08678422,\n",
       "       -0.386454  ,  0.16256103,  0.1217219 ,  0.12082722, -0.16816677,\n",
       "       -0.2042402 ,  0.16236259, -0.19501297, -0.07939766, -0.39770865,\n",
       "        0.05372566, -0.08045243, -0.14662999,  0.06458273, -0.2573889 ,\n",
       "       -0.281443  , -0.29033786, -0.115464  , -0.05995635,  0.1473302 ,\n",
       "       -0.44251707,  0.37240022, -0.01774769, -0.10461881, -0.01123857,\n",
       "       -0.07304859, -0.26970956, -0.2605545 ,  0.04561565,  0.08572383,\n",
       "        0.2348939 , -0.054392  ,  0.37166077,  0.10470071, -0.01097885,\n",
       "       -0.23123284,  0.21916398,  0.39577535, -0.2132875 ,  0.06510614,\n",
       "       -0.34041595,  0.30591702,  0.24471003, -0.1280433 , -0.22523123,\n",
       "       -0.04215761,  0.0472334 , -0.15375209, -0.04366542, -0.01707038,\n",
       "       -0.14829369, -0.22785361,  0.31880978, -0.03544043, -0.3213902 ,\n",
       "        0.31475532,  0.07446518, -0.00634289, -0.12944895, -0.03159433,\n",
       "       -0.15371487,  0.3288587 ,  0.17360218,  0.07215934,  0.10763504,\n",
       "       -0.1385645 ,  0.3476268 , -0.44851482,  0.07603835,  0.21655263,\n",
       "       -0.17388488, -0.16590264,  0.03924661,  0.16923189,  0.15807115,\n",
       "        0.1254363 ,  0.20440318, -0.08067098, -0.09459051,  0.3444574 ,\n",
       "        0.08846354,  0.70334655, -0.11520722, -0.11151797,  0.32419193,\n",
       "       -0.04690797, -0.17465481,  0.14408901, -0.29436386,  0.34019792,\n",
       "       -0.00524671,  0.66233784, -0.23463583,  0.02839188, -0.19074172,\n",
       "        0.6270245 ,  0.2002685 , -0.22945765, -0.2230347 ,  0.06279671,\n",
       "       -0.15022571, -0.45568752,  0.2682225 ,  0.43079904,  0.3308453 ,\n",
       "        0.16380088,  0.07941155,  0.12186207,  0.02604837, -0.15751651,\n",
       "        0.3291047 , -0.32007927, -0.0563377 ,  0.00084251, -0.1302275 ,\n",
       "        0.03523461, -0.02872314,  0.46195933, -0.2932325 , -0.65862036,\n",
       "       -0.5634222 ,  0.2964952 , -0.07000981, -0.40975535, -0.37702167],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['nasdaq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fv9LHwFnFbVL",
    "outputId": "0cc632eb-0bce-4142-82cc-eebd6a9f4233"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_w2v.wv['nasdaq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DtGMZsEtFbVO",
    "outputId": "17471289-6528-4096-d92d-75a15ab4cdf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDptzTF5FbVR"
   },
   "source": [
    "##### 3.4.1.Preparing Vectors for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6gYlrrnFbVR"
   },
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary           \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsQ8RMMTFbVT"
   },
   "source": [
    "##### 3.4.2.Preparing word2vec feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "t8PBWT-BFbVU",
    "outputId": "5f34e382-4809-49f5-d1db-6d42df92af8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201549</td>\n",
       "      <td>-0.058880</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.223172</td>\n",
       "      <td>0.180056</td>\n",
       "      <td>0.188836</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>-0.237002</td>\n",
       "      <td>0.175908</td>\n",
       "      <td>0.168333</td>\n",
       "      <td>0.400366</td>\n",
       "      <td>-0.097706</td>\n",
       "      <td>0.339135</td>\n",
       "      <td>-0.493795</td>\n",
       "      <td>-0.143372</td>\n",
       "      <td>0.136877</td>\n",
       "      <td>-0.155490</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>0.239460</td>\n",
       "      <td>-0.241012</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>-0.058397</td>\n",
       "      <td>-0.036771</td>\n",
       "      <td>-0.039228</td>\n",
       "      <td>0.077104</td>\n",
       "      <td>0.060888</td>\n",
       "      <td>-0.138675</td>\n",
       "      <td>0.189417</td>\n",
       "      <td>-0.366141</td>\n",
       "      <td>0.193656</td>\n",
       "      <td>0.105065</td>\n",
       "      <td>-0.137805</td>\n",
       "      <td>0.044918</td>\n",
       "      <td>-0.063056</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>0.145569</td>\n",
       "      <td>-0.053161</td>\n",
       "      <td>-0.098633</td>\n",
       "      <td>0.118543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108190</td>\n",
       "      <td>-0.039113</td>\n",
       "      <td>0.203187</td>\n",
       "      <td>-0.069502</td>\n",
       "      <td>-0.126691</td>\n",
       "      <td>0.050342</td>\n",
       "      <td>-0.292074</td>\n",
       "      <td>0.208550</td>\n",
       "      <td>0.061030</td>\n",
       "      <td>-0.105535</td>\n",
       "      <td>0.419986</td>\n",
       "      <td>-0.170998</td>\n",
       "      <td>-0.188886</td>\n",
       "      <td>-0.254052</td>\n",
       "      <td>-0.097026</td>\n",
       "      <td>0.107523</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.167282</td>\n",
       "      <td>0.111037</td>\n",
       "      <td>0.131010</td>\n",
       "      <td>-0.007265</td>\n",
       "      <td>-0.172760</td>\n",
       "      <td>-0.145243</td>\n",
       "      <td>0.177934</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>0.040244</td>\n",
       "      <td>-0.189848</td>\n",
       "      <td>0.274110</td>\n",
       "      <td>0.189838</td>\n",
       "      <td>-0.190380</td>\n",
       "      <td>-0.160189</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>-0.043201</td>\n",
       "      <td>-0.130171</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>-0.102300</td>\n",
       "      <td>0.389710</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>-0.295826</td>\n",
       "      <td>-0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219597</td>\n",
       "      <td>-0.160597</td>\n",
       "      <td>0.166340</td>\n",
       "      <td>0.089833</td>\n",
       "      <td>0.047616</td>\n",
       "      <td>0.276412</td>\n",
       "      <td>0.218447</td>\n",
       "      <td>-0.017701</td>\n",
       "      <td>0.235180</td>\n",
       "      <td>-0.197354</td>\n",
       "      <td>0.054539</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>-0.296322</td>\n",
       "      <td>-0.056736</td>\n",
       "      <td>0.069059</td>\n",
       "      <td>-0.071355</td>\n",
       "      <td>0.288428</td>\n",
       "      <td>-0.243389</td>\n",
       "      <td>-0.167503</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.129679</td>\n",
       "      <td>-0.125811</td>\n",
       "      <td>-0.115843</td>\n",
       "      <td>0.038420</td>\n",
       "      <td>-0.087136</td>\n",
       "      <td>-0.052440</td>\n",
       "      <td>0.092082</td>\n",
       "      <td>-0.242383</td>\n",
       "      <td>0.319137</td>\n",
       "      <td>0.226937</td>\n",
       "      <td>0.042859</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>-0.019998</td>\n",
       "      <td>0.137297</td>\n",
       "      <td>-0.357740</td>\n",
       "      <td>0.058410</td>\n",
       "      <td>0.098637</td>\n",
       "      <td>0.152728</td>\n",
       "      <td>0.084178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288100</td>\n",
       "      <td>-0.109103</td>\n",
       "      <td>0.391574</td>\n",
       "      <td>-0.122902</td>\n",
       "      <td>-0.120003</td>\n",
       "      <td>0.052285</td>\n",
       "      <td>0.161362</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.215084</td>\n",
       "      <td>0.343570</td>\n",
       "      <td>0.131715</td>\n",
       "      <td>0.045053</td>\n",
       "      <td>0.123937</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>-0.401386</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>-0.167026</td>\n",
       "      <td>-0.114807</td>\n",
       "      <td>0.143618</td>\n",
       "      <td>0.099672</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>-0.122294</td>\n",
       "      <td>-0.180833</td>\n",
       "      <td>0.107290</td>\n",
       "      <td>0.169298</td>\n",
       "      <td>0.074593</td>\n",
       "      <td>0.200640</td>\n",
       "      <td>0.230538</td>\n",
       "      <td>0.060314</td>\n",
       "      <td>-0.057462</td>\n",
       "      <td>-0.048102</td>\n",
       "      <td>-0.198468</td>\n",
       "      <td>0.216565</td>\n",
       "      <td>-0.100224</td>\n",
       "      <td>-0.426578</td>\n",
       "      <td>-0.105106</td>\n",
       "      <td>0.609833</td>\n",
       "      <td>0.150369</td>\n",
       "      <td>0.085569</td>\n",
       "      <td>-0.130088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068557</td>\n",
       "      <td>-0.153593</td>\n",
       "      <td>0.196505</td>\n",
       "      <td>0.279166</td>\n",
       "      <td>0.115757</td>\n",
       "      <td>0.131893</td>\n",
       "      <td>0.287359</td>\n",
       "      <td>-0.223620</td>\n",
       "      <td>0.352287</td>\n",
       "      <td>0.065734</td>\n",
       "      <td>-0.060602</td>\n",
       "      <td>-0.144413</td>\n",
       "      <td>0.134020</td>\n",
       "      <td>-0.259040</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.096336</td>\n",
       "      <td>-0.272190</td>\n",
       "      <td>0.223377</td>\n",
       "      <td>-0.325389</td>\n",
       "      <td>-0.318443</td>\n",
       "      <td>0.049387</td>\n",
       "      <td>0.105697</td>\n",
       "      <td>0.093770</td>\n",
       "      <td>0.089876</td>\n",
       "      <td>0.102705</td>\n",
       "      <td>-0.060413</td>\n",
       "      <td>0.033723</td>\n",
       "      <td>0.244376</td>\n",
       "      <td>-0.123585</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>0.060062</td>\n",
       "      <td>-0.132571</td>\n",
       "      <td>0.147042</td>\n",
       "      <td>-0.119347</td>\n",
       "      <td>0.089759</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.058693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029265</td>\n",
       "      <td>-0.144180</td>\n",
       "      <td>0.171024</td>\n",
       "      <td>-0.126562</td>\n",
       "      <td>-0.079471</td>\n",
       "      <td>0.301216</td>\n",
       "      <td>0.088441</td>\n",
       "      <td>0.062065</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>0.035766</td>\n",
       "      <td>0.249980</td>\n",
       "      <td>-0.244441</td>\n",
       "      <td>-0.149104</td>\n",
       "      <td>-0.466875</td>\n",
       "      <td>-0.100066</td>\n",
       "      <td>-0.073692</td>\n",
       "      <td>-0.088428</td>\n",
       "      <td>0.155025</td>\n",
       "      <td>-0.012406</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>0.101945</td>\n",
       "      <td>0.037484</td>\n",
       "      <td>0.083273</td>\n",
       "      <td>0.122808</td>\n",
       "      <td>0.151421</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>-0.102749</td>\n",
       "      <td>0.283339</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>-0.139026</td>\n",
       "      <td>-0.223437</td>\n",
       "      <td>0.168517</td>\n",
       "      <td>-0.052230</td>\n",
       "      <td>-0.197929</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>0.081422</td>\n",
       "      <td>-0.033059</td>\n",
       "      <td>-0.080726</td>\n",
       "      <td>0.033157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145885</td>\n",
       "      <td>-0.114159</td>\n",
       "      <td>0.145472</td>\n",
       "      <td>0.203797</td>\n",
       "      <td>0.180099</td>\n",
       "      <td>0.255026</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>-0.146707</td>\n",
       "      <td>0.382357</td>\n",
       "      <td>-0.038965</td>\n",
       "      <td>0.035106</td>\n",
       "      <td>0.122333</td>\n",
       "      <td>0.326634</td>\n",
       "      <td>-0.423494</td>\n",
       "      <td>-0.132386</td>\n",
       "      <td>0.107922</td>\n",
       "      <td>-0.198404</td>\n",
       "      <td>0.141435</td>\n",
       "      <td>-0.005548</td>\n",
       "      <td>-0.151942</td>\n",
       "      <td>-0.052321</td>\n",
       "      <td>-0.096661</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>0.144787</td>\n",
       "      <td>0.044767</td>\n",
       "      <td>-0.055905</td>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.113796</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>0.059798</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.123884</td>\n",
       "      <td>0.132430</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>-0.061047</td>\n",
       "      <td>-0.176002</td>\n",
       "      <td>0.208373</td>\n",
       "      <td>0.035253</td>\n",
       "      <td>0.127397</td>\n",
       "      <td>0.145189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170562</td>\n",
       "      <td>-0.017938</td>\n",
       "      <td>-0.044600</td>\n",
       "      <td>-0.294726</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>-0.027945</td>\n",
       "      <td>0.356192</td>\n",
       "      <td>-0.120101</td>\n",
       "      <td>-0.017419</td>\n",
       "      <td>0.340788</td>\n",
       "      <td>-0.251561</td>\n",
       "      <td>-0.222637</td>\n",
       "      <td>-0.180434</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>0.071818</td>\n",
       "      <td>-0.104818</td>\n",
       "      <td>0.193944</td>\n",
       "      <td>0.158525</td>\n",
       "      <td>0.081381</td>\n",
       "      <td>0.044801</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>-0.137656</td>\n",
       "      <td>0.194172</td>\n",
       "      <td>0.148202</td>\n",
       "      <td>-0.054651</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>0.098264</td>\n",
       "      <td>-0.084219</td>\n",
       "      <td>-0.111890</td>\n",
       "      <td>-0.085854</td>\n",
       "      <td>-0.260783</td>\n",
       "      <td>0.091261</td>\n",
       "      <td>-0.200442</td>\n",
       "      <td>-0.179743</td>\n",
       "      <td>-0.076632</td>\n",
       "      <td>0.139646</td>\n",
       "      <td>0.103295</td>\n",
       "      <td>-0.073316</td>\n",
       "      <td>-0.070356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188864</td>\n",
       "      <td>-0.343754</td>\n",
       "      <td>0.201325</td>\n",
       "      <td>0.165398</td>\n",
       "      <td>0.301113</td>\n",
       "      <td>0.339103</td>\n",
       "      <td>0.172763</td>\n",
       "      <td>-0.165950</td>\n",
       "      <td>0.477747</td>\n",
       "      <td>0.123165</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.092101</td>\n",
       "      <td>-0.016997</td>\n",
       "      <td>-0.467255</td>\n",
       "      <td>-0.070210</td>\n",
       "      <td>-0.072310</td>\n",
       "      <td>-0.111554</td>\n",
       "      <td>0.170839</td>\n",
       "      <td>-0.193572</td>\n",
       "      <td>-0.324694</td>\n",
       "      <td>-0.111662</td>\n",
       "      <td>-0.114044</td>\n",
       "      <td>0.169130</td>\n",
       "      <td>-0.066418</td>\n",
       "      <td>0.176054</td>\n",
       "      <td>-0.247058</td>\n",
       "      <td>0.135439</td>\n",
       "      <td>0.100032</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.228698</td>\n",
       "      <td>0.092868</td>\n",
       "      <td>0.189334</td>\n",
       "      <td>0.095383</td>\n",
       "      <td>-0.099921</td>\n",
       "      <td>0.094894</td>\n",
       "      <td>-0.181975</td>\n",
       "      <td>0.026453</td>\n",
       "      <td>0.096115</td>\n",
       "      <td>-0.156544</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252864</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.156052</td>\n",
       "      <td>-0.256226</td>\n",
       "      <td>0.040098</td>\n",
       "      <td>0.153394</td>\n",
       "      <td>-0.084524</td>\n",
       "      <td>-0.013671</td>\n",
       "      <td>-0.039235</td>\n",
       "      <td>-0.042070</td>\n",
       "      <td>0.325697</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>-0.212633</td>\n",
       "      <td>-0.211698</td>\n",
       "      <td>0.166788</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>0.446825</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>-0.106501</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>0.207154</td>\n",
       "      <td>0.327420</td>\n",
       "      <td>0.148758</td>\n",
       "      <td>-0.051584</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>0.276817</td>\n",
       "      <td>0.231715</td>\n",
       "      <td>0.089713</td>\n",
       "      <td>0.288810</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.177812</td>\n",
       "      <td>-0.111687</td>\n",
       "      <td>-0.192715</td>\n",
       "      <td>-0.357444</td>\n",
       "      <td>0.129014</td>\n",
       "      <td>0.360462</td>\n",
       "      <td>-0.056897</td>\n",
       "      <td>-0.303038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    ...       197       198       199\n",
       "0  0.201549 -0.058880  0.098633  ...  0.029564 -0.295826 -0.001734\n",
       "1  0.219597 -0.160597  0.166340  ...  0.150369  0.085569 -0.130088\n",
       "2  0.068557 -0.153593  0.196505  ... -0.033059 -0.080726  0.033157\n",
       "3  0.145885 -0.114159  0.145472  ...  0.103295 -0.073316 -0.070356\n",
       "4  0.188864 -0.343754  0.201325  ...  0.360462 -0.056897 -0.303038\n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_text), 200)) \n",
    "for i in range(len(tokenized_text)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_text[i], 200)\n",
    "    wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0IiyQB40FbVW",
    "outputId": "f8d0358f-4bc2-4566-8331-8ce91c4aab19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHAutyVQJIKJ"
   },
   "source": [
    "#### 3.4.3.transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "v1AMurZuI-Mp",
    "outputId": "e5ffa6c8-ab65-4d88-eaed-11e66be9603d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153245</td>\n",
       "      <td>iPhone 6 Release Date Pushed Back Due to Issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308611</td>\n",
       "      <td>Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title\n",
       "0      153245  iPhone 6 Release Date Pushed Back Due to Issue...\n",
       "1      308611  Samsung Galaxy S4 vs Galaxy S3: Budget-Friendl..."
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd72wMEjI-T_"
   },
   "outputs": [],
   "source": [
    "tokenized_text_test = feature_test['title'].apply(lambda x: x.split()) # tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "fduT1yupJz9_",
    "outputId": "0181eb49-4950-4213-c430-5de273b84231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208947</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>0.179379</td>\n",
       "      <td>0.280777</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>0.867512</td>\n",
       "      <td>0.257228</td>\n",
       "      <td>-0.461147</td>\n",
       "      <td>0.173479</td>\n",
       "      <td>-0.048893</td>\n",
       "      <td>0.307089</td>\n",
       "      <td>-0.242034</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>-0.498594</td>\n",
       "      <td>-0.159750</td>\n",
       "      <td>0.281571</td>\n",
       "      <td>-0.055472</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>-0.111137</td>\n",
       "      <td>-0.148030</td>\n",
       "      <td>-0.360053</td>\n",
       "      <td>-0.225036</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>-0.036454</td>\n",
       "      <td>-0.143800</td>\n",
       "      <td>-0.410052</td>\n",
       "      <td>-0.226629</td>\n",
       "      <td>0.139980</td>\n",
       "      <td>0.242914</td>\n",
       "      <td>0.445334</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>-0.137722</td>\n",
       "      <td>-0.345805</td>\n",
       "      <td>-0.335670</td>\n",
       "      <td>-0.043771</td>\n",
       "      <td>0.398432</td>\n",
       "      <td>0.164009</td>\n",
       "      <td>-0.017230</td>\n",
       "      <td>0.185658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063325</td>\n",
       "      <td>-0.179066</td>\n",
       "      <td>0.041801</td>\n",
       "      <td>-0.036524</td>\n",
       "      <td>-0.411031</td>\n",
       "      <td>0.187748</td>\n",
       "      <td>-0.151222</td>\n",
       "      <td>0.010793</td>\n",
       "      <td>-0.250380</td>\n",
       "      <td>-0.122431</td>\n",
       "      <td>0.059570</td>\n",
       "      <td>0.046637</td>\n",
       "      <td>-0.592476</td>\n",
       "      <td>-0.817895</td>\n",
       "      <td>-0.336659</td>\n",
       "      <td>-0.215695</td>\n",
       "      <td>-0.259888</td>\n",
       "      <td>-0.079524</td>\n",
       "      <td>0.241328</td>\n",
       "      <td>-0.026151</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>-0.475204</td>\n",
       "      <td>-0.033057</td>\n",
       "      <td>0.405606</td>\n",
       "      <td>-0.379209</td>\n",
       "      <td>-0.070627</td>\n",
       "      <td>-0.185800</td>\n",
       "      <td>0.637822</td>\n",
       "      <td>-0.074722</td>\n",
       "      <td>-0.289431</td>\n",
       "      <td>-0.214507</td>\n",
       "      <td>-0.586476</td>\n",
       "      <td>0.319888</td>\n",
       "      <td>-0.370352</td>\n",
       "      <td>-0.313744</td>\n",
       "      <td>-0.162246</td>\n",
       "      <td>0.262717</td>\n",
       "      <td>0.124041</td>\n",
       "      <td>0.060021</td>\n",
       "      <td>0.161705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289732</td>\n",
       "      <td>-0.248723</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>0.239139</td>\n",
       "      <td>0.127363</td>\n",
       "      <td>-0.248794</td>\n",
       "      <td>-0.509878</td>\n",
       "      <td>-0.133230</td>\n",
       "      <td>0.472773</td>\n",
       "      <td>0.436935</td>\n",
       "      <td>0.317511</td>\n",
       "      <td>0.460440</td>\n",
       "      <td>-0.116106</td>\n",
       "      <td>-0.495276</td>\n",
       "      <td>-0.184468</td>\n",
       "      <td>-0.469791</td>\n",
       "      <td>-0.162628</td>\n",
       "      <td>0.214155</td>\n",
       "      <td>-0.369042</td>\n",
       "      <td>0.422644</td>\n",
       "      <td>-0.356284</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>-0.297467</td>\n",
       "      <td>0.590991</td>\n",
       "      <td>0.304082</td>\n",
       "      <td>-0.333202</td>\n",
       "      <td>-0.220233</td>\n",
       "      <td>-0.025756</td>\n",
       "      <td>-0.160637</td>\n",
       "      <td>-0.329871</td>\n",
       "      <td>-0.376956</td>\n",
       "      <td>0.285357</td>\n",
       "      <td>-0.287015</td>\n",
       "      <td>0.112305</td>\n",
       "      <td>0.037366</td>\n",
       "      <td>0.548521</td>\n",
       "      <td>-0.483419</td>\n",
       "      <td>-0.246519</td>\n",
       "      <td>0.081826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387250</td>\n",
       "      <td>0.164938</td>\n",
       "      <td>0.267385</td>\n",
       "      <td>-0.280190</td>\n",
       "      <td>-0.463488</td>\n",
       "      <td>0.129127</td>\n",
       "      <td>0.160741</td>\n",
       "      <td>0.221796</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>-0.090803</td>\n",
       "      <td>0.765732</td>\n",
       "      <td>0.084728</td>\n",
       "      <td>-0.436326</td>\n",
       "      <td>-0.407389</td>\n",
       "      <td>0.102193</td>\n",
       "      <td>0.175556</td>\n",
       "      <td>-0.261573</td>\n",
       "      <td>-0.091003</td>\n",
       "      <td>-0.062443</td>\n",
       "      <td>0.194060</td>\n",
       "      <td>0.388039</td>\n",
       "      <td>0.403039</td>\n",
       "      <td>-0.073053</td>\n",
       "      <td>-0.009276</td>\n",
       "      <td>0.509792</td>\n",
       "      <td>0.045316</td>\n",
       "      <td>-0.396843</td>\n",
       "      <td>-0.104715</td>\n",
       "      <td>-0.163059</td>\n",
       "      <td>0.095767</td>\n",
       "      <td>-0.602258</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.122325</td>\n",
       "      <td>-0.290399</td>\n",
       "      <td>-0.441995</td>\n",
       "      <td>-0.590126</td>\n",
       "      <td>0.364988</td>\n",
       "      <td>0.422009</td>\n",
       "      <td>-0.721807</td>\n",
       "      <td>0.372950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020771</td>\n",
       "      <td>-0.480825</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.213706</td>\n",
       "      <td>0.300395</td>\n",
       "      <td>0.319023</td>\n",
       "      <td>0.249774</td>\n",
       "      <td>-0.214976</td>\n",
       "      <td>0.145893</td>\n",
       "      <td>-0.212840</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>-0.452445</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>-0.124101</td>\n",
       "      <td>0.074724</td>\n",
       "      <td>0.123463</td>\n",
       "      <td>-0.244625</td>\n",
       "      <td>0.308892</td>\n",
       "      <td>-0.045261</td>\n",
       "      <td>-0.020364</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.311494</td>\n",
       "      <td>-0.036514</td>\n",
       "      <td>-0.098276</td>\n",
       "      <td>-0.112019</td>\n",
       "      <td>0.137699</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>-0.036999</td>\n",
       "      <td>0.055497</td>\n",
       "      <td>0.180919</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>0.128892</td>\n",
       "      <td>-0.306811</td>\n",
       "      <td>0.075289</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.015532</td>\n",
       "      <td>-0.106327</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>-0.018959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124567</td>\n",
       "      <td>-0.104154</td>\n",
       "      <td>0.084601</td>\n",
       "      <td>-0.079162</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.225159</td>\n",
       "      <td>0.300026</td>\n",
       "      <td>0.148079</td>\n",
       "      <td>0.030213</td>\n",
       "      <td>0.213160</td>\n",
       "      <td>0.175331</td>\n",
       "      <td>0.074395</td>\n",
       "      <td>-0.347344</td>\n",
       "      <td>-0.187774</td>\n",
       "      <td>-0.159730</td>\n",
       "      <td>-0.003938</td>\n",
       "      <td>-0.157141</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.085069</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>-0.178259</td>\n",
       "      <td>0.225099</td>\n",
       "      <td>-0.031960</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>0.123214</td>\n",
       "      <td>0.129897</td>\n",
       "      <td>0.170347</td>\n",
       "      <td>0.235304</td>\n",
       "      <td>0.161928</td>\n",
       "      <td>-0.154995</td>\n",
       "      <td>-0.033598</td>\n",
       "      <td>0.224820</td>\n",
       "      <td>-0.091931</td>\n",
       "      <td>-0.324775</td>\n",
       "      <td>0.112336</td>\n",
       "      <td>0.217432</td>\n",
       "      <td>0.145830</td>\n",
       "      <td>-0.117171</td>\n",
       "      <td>-0.132957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    ...       197       198       199\n",
       "0  0.208947 -0.076844  0.179379  ...  0.124041  0.060021  0.161705\n",
       "1  0.289732 -0.248723  0.023323  ...  0.422009 -0.721807  0.372950\n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
       "4  0.020771 -0.480825  0.128506  ...  0.145830 -0.117171 -0.132957\n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_text_test), 200)) \n",
    "for i in range(len(tokenized_text_test)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_text_test[i], 200)\n",
    "    wordvec_df_test = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "p_HxOoDzKLha",
    "outputId": "b7f742b9-46e6-41b1-f852-3aa354fd55a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(84484, 200)\n"
     ]
    }
   ],
   "source": [
    "print(wordvec_df.shape)\n",
    "print(wordvec_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsNzXAmuKR_o"
   },
   "source": [
    "It may look weird as we have less data for train and more to test. But, training is computing intense. So, this will help us. Plus eventually I will train my best performing model to whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdnJk36HFbVY"
   },
   "source": [
    "# 4)-Model Building\n",
    "\n",
    "- Logistic Regression \n",
    "- Support Vector\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZyB6Ih2FbVZ"
   },
   "source": [
    "### 4.1.Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXwWhdpAFbVZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve,roc_auc_score,confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb7nG3LxFbVc"
   },
   "source": [
    "##### 4.1.a. Logistic Regression using Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "5iEJ9RfsFbVc",
    "outputId": "b8be0cc2-0e61-470b-fe32-fd83134d3252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=bow\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bow_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQPg-YXfFbVf"
   },
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "#xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(bow, y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "jweLRi-aFbVj",
    "outputId": "205cac1e-3f35-43f7-e15e-659a1222ffe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_bow = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# training the model\n",
    "lreg_bow.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ImmHJhilFbVl",
    "outputId": "35988bb0-91ed-4f19-e63b-da9fd7b61216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16087434, 0.6072539 , 0.04823555, 0.1836362 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the validation set\n",
    "prediction_bow = lreg_bow.predict_proba(bow_test)\n",
    "prediction_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "beAraqzwFbVn",
    "outputId": "b85476a8-24f4-47ca-9d06-303ddde5e000"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction over classes\n",
    "\n",
    "prediction_bow_class=lreg_bow.predict(bow_test)\n",
    "prediction_bow_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jGz9B4YfFbVp",
    "outputId": "057575be-9f59-44ff-92c0-4bed5ddda2ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7044765872827992"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label_test, prediction_bow_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "B4Dldo8nPaJR",
    "outputId": "95d8460e-3bd6-48d1-ed2b-079a2c5dafa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.73      0.65      0.69     23367\n",
      "           e       0.65      0.92      0.76     30300\n",
      "           m       0.75      0.47      0.58      9207\n",
      "           t       0.80      0.56      0.66     21610\n",
      "\n",
      "    accuracy                           0.70     84484\n",
      "   macro avg       0.73      0.65      0.67     84484\n",
      "weighted avg       0.72      0.70      0.70     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(label_test, prediction_bow_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBGrdDU_FbVr"
   },
   "source": [
    "##### 4.1.b.Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "zfgu8I2iFbVs",
    "outputId": "d0977465-0f68-45b2-d8d3-7ad2989720db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "oqNxBx1xFbVz",
    "outputId": "ea3a8736-17c9-462f-803f-b759bbf7f84f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_tfidf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# training the model\n",
    "lreg_tfidf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-VNi8euFbV2"
   },
   "outputs": [],
   "source": [
    "# predicting on the validation set\n",
    "prediction_tfidf = lreg_tfidf.predict_proba(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQJRDvn2FbV5"
   },
   "outputs": [],
   "source": [
    "prediction_tfidf_class=lreg_tfidf.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "okZ87DBgFbV7",
    "outputId": "214d2037-2145-4589-a9ef-4b5ef56c38bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707542256521945"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label_test, prediction_tfidf_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "n9KoqxK_Pp4d",
    "outputId": "a03d1024-3299-41ae-8e15-29db59bfcdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.73      0.66      0.69     23367\n",
      "           e       0.66      0.92      0.77     30300\n",
      "           m       0.78      0.46      0.58      9207\n",
      "           t       0.79      0.57      0.66     21610\n",
      "\n",
      "    accuracy                           0.71     84484\n",
      "   macro avg       0.74      0.65      0.67     84484\n",
      "weighted avg       0.72      0.71      0.70     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_tfidf_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbk9ltufFbV9"
   },
   "source": [
    "##### 4.1.c. Logistic Regression using Word2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "OmI6mOKBQ2dC",
    "outputId": "b7660831-38ca-416d-ef18-f042ab66b8b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(wordvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "9C1WP4QXFbWF",
    "outputId": "cc6740ad-bde9-4960-849f-e4c1ef53736c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_word2vec = LogisticRegression(solver='liblinear')\n",
    "# training the model\n",
    "lreg_word2vec.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LyeoWGCFbWH"
   },
   "outputs": [],
   "source": [
    "# predicting on the validation set\n",
    "prediction_word2vec = lreg_word2vec.predict_proba(wordvec_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-BmMTfGFbWK"
   },
   "outputs": [],
   "source": [
    "prediction_word2vec_class=lreg_word2vec.predict(wordvec_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FBF4vlsoFbWM",
    "outputId": "317adbb6-dba8-4716-c7a2-2a5b00d6fe26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4234884711898111"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label_test, prediction_word2vec_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "AjtoZOewRy49",
    "outputId": "e01aceef-866a-451d-b1ed-50d5ad798019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.35      0.79      0.48     23367\n",
      "           e       0.61      0.31      0.41     30300\n",
      "           m       0.43      0.33      0.38      9207\n",
      "           t       0.56      0.22      0.32     21610\n",
      "\n",
      "    accuracy                           0.42     84484\n",
      "   macro avg       0.49      0.41      0.40     84484\n",
      "weighted avg       0.51      0.42      0.40     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_word2vec_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg0Ym9JbFbWS"
   },
   "source": [
    "##### 4.1.d. Logistic Regression using Doc2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ZV37T5DCFbWT",
    "outputId": "fc0ad5fe-6818-4078-8429-0ce8b7c7e9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=docvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(docvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "HA8Qd5_LFbWX",
    "outputId": "d0899c03-1177-40f8-e83f-7a069cf7e550"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_doc2vec = LogisticRegression(solver='liblinear')\n",
    "# training the model\n",
    "lreg_doc2vec.fit(docvec_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhmb_OTDFbWZ"
   },
   "outputs": [],
   "source": [
    "# predicting on the validation set\n",
    "prediction_doc2vec = lreg_doc2vec.predict_proba(docvec_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGKC4_iIFbWb"
   },
   "outputs": [],
   "source": [
    "prediction_doc2vec_class=lreg_doc2vec.predict(docvec_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y-iMtZoaFbWd",
    "outputId": "2df5c863-04d3-4c5b-9229-a1f6076dc9cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35864779129776053"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label_test, prediction_doc2vec_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "dwYQYPmSUiFl",
    "outputId": "1c70fed6-5b2b-4b7b-ddc3-b729befc35e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.00      0.00      0.00     23367\n",
      "           e       0.36      1.00      0.53     30300\n",
      "           m       0.00      0.00      0.00      9207\n",
      "           t       0.00      0.00      0.00     21610\n",
      "\n",
      "    accuracy                           0.36     84484\n",
      "   macro avg       0.09      0.25      0.13     84484\n",
      "weighted avg       0.13      0.36      0.19     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_doc2vec_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KxYIn4YHFbWf"
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- bow=70%\n",
    "- tfidf=70%\n",
    "- word2vec=33%\n",
    "- doc2vec=35%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwtZ0MegFbWg"
   },
   "source": [
    "### 4.2.Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "gmTrS_uvYZ3M",
    "outputId": "6a20503b-38b9-4300-9dca-57c641158ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=bow\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bow_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "en7vF4vcFbWg"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr57vBb5FbWi"
   },
   "source": [
    "##### SVM using Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIhUSGKTW0Mt"
   },
   "outputs": [],
   "source": [
    "# we need to input arrays to our model.\n",
    "bow_test = bow_vectorizer.transform(feature_test[\"title\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pABptDhnFbWi"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNztkbM1YxkD"
   },
   "outputs": [],
   "source": [
    "#prediction = svc.predict_proba(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqvkDLfMYFdG"
   },
   "outputs": [],
   "source": [
    "prediction_class = svc.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xQ6Hb7mbFbWl",
    "outputId": "9eed8b3b-048f-418a-8836-be9f236835d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6848752426494957"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "EiF0Q-OcWJJw",
    "outputId": "c2189e97-5f75-499a-ba8f-c47f7c66cfb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.71      0.64      0.67     23367\n",
      "           e       0.63      0.92      0.75     30300\n",
      "           m       0.72      0.45      0.56      9207\n",
      "           t       0.81      0.50      0.62     21610\n",
      "\n",
      "    accuracy                           0.68     84484\n",
      "   macro avg       0.72      0.63      0.65     84484\n",
      "weighted avg       0.71      0.68      0.67     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVQB0C2ZFbWn"
   },
   "source": [
    "##### SVM using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "HndR9SfrglTs",
    "outputId": "984373f9-6139-4314-8600-2e85fb72d107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfU0rkR9gqHA"
   },
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TlyLu38TFbWn",
    "outputId": "00fafb13-a1e3-4dbd-a509-8faa186322e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975521992329908"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='linear',C=1, probability=True).fit(X,y)\n",
    "#prediction = svc.predict_proba(xvalid_tfidf)\n",
    "prediction_class = svc.predict(tfidf_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "XqQRlfcqhBuI",
    "outputId": "3768870b-909e-40c5-ba7f-20b4c00f8049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.72      0.65      0.68     23367\n",
      "           e       0.65      0.91      0.76     30300\n",
      "           m       0.74      0.46      0.57      9207\n",
      "           t       0.79      0.55      0.65     21610\n",
      "\n",
      "    accuracy                           0.70     84484\n",
      "   macro avg       0.72      0.64      0.66     84484\n",
      "weighted avg       0.71      0.70      0.69     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PV_qfYBqFbWo"
   },
   "source": [
    "##### SVM using word2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "e7Yi1ZnMhMip",
    "outputId": "0f338147-c058-4cf5-a7d1-9e5b8e84f10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(wordvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jS45LSgBFbWp"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(X,y)\n",
    "#prediction = svc.predict_proba(wordvec_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6zkhI1gBhXGd",
    "outputId": "30cebf0b-95cc-4218-937a-374c62d1df35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42191420860754697"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_class = svc.predict(wordvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "pZLdcD9khexi",
    "outputId": "7d191aeb-e8c1-4737-d710-f7a379d276a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.34      0.80      0.48     23367\n",
      "           e       0.63      0.30      0.40     30300\n",
      "           m       0.43      0.35      0.39      9207\n",
      "           t       0.55      0.22      0.32     21610\n",
      "\n",
      "    accuracy                           0.42     84484\n",
      "   macro avg       0.49      0.42      0.40     84484\n",
      "weighted avg       0.51      0.42      0.40     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ieV0FKFFbWr"
   },
   "source": [
    "##### SVM using doc2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "2nawyZ6UiKl9",
    "outputId": "ee3f8721-ccb4-4169-ddf7-79d2e93ada7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=docvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(docvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iU64CelSFbWr"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xcB-C3xWiNZZ",
    "outputId": "ead31ffc-f218-4fba-891c-7bfd5ae55a09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35864779129776053"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction = svc.predict_proba(xvalid_doc2vec)\n",
    "prediction_class = svc.predict(docvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "wW1YCuYMiZvx",
    "outputId": "b5534dec-65e4-4226-b1ac-54698ffb82f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.00      0.00      0.00     23367\n",
      "           e       0.36      1.00      0.53     30300\n",
      "           m       0.00      0.00      0.00      9207\n",
      "           t       0.00      0.00      0.00     21610\n",
      "\n",
      "    accuracy                           0.36     84484\n",
      "   macro avg       0.09      0.25      0.13     84484\n",
      "weighted avg       0.13      0.36      0.19     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgh6Ar7GFbWt"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "\n",
    "- bow = 69%\n",
    "- tfidf= 68%\n",
    "- word2vec= 42% \n",
    "- doc2vec= 41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8aNqsLFFbWt"
   },
   "source": [
    "### 4.3.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ps80pvJFbWt"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWQK6PgIFbWv"
   },
   "source": [
    "##### RF with Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "4hfLFSajjQdd",
    "outputId": "7af96162-b9af-480c-c47d-8212fa567e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=bow\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bow_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdTIiauAFbWv"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y_7riy9FjXdt",
    "outputId": "e815c6e3-eed5-4136-f6a4-ae58202b35f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654088348089579"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction = rf.predict_proba(xvalid_bow)\n",
    "prediction_class = rf.predict(bow_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6eFxNneFbWw"
   },
   "source": [
    "##### RF with TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "NUusgEo1kV9l",
    "outputId": "a9bc8c3e-f004-4104-b330-ed7d5fc27d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifOtWDDcFbWx"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qle8SSZOkej0",
    "outputId": "3a65aef0-c604-4a66-86b3-068d1091c70c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6657591970077175"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction = rf.predict_proba(xvalid_tfidf)\n",
    "prediction_class = rf.predict(tfidf_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "8knPT4GwknNY",
    "outputId": "d697e439-9bf6-41e5-a04e-c729a13d25b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.70      0.61      0.65     23367\n",
      "           e       0.64      0.87      0.73     30300\n",
      "           m       0.61      0.47      0.53      9207\n",
      "           t       0.73      0.52      0.61     21610\n",
      "\n",
      "    accuracy                           0.67     84484\n",
      "   macro avg       0.67      0.62      0.63     84484\n",
      "weighted avg       0.67      0.67      0.66     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkqeNM_FFbWy"
   },
   "source": [
    "##### RF with word2vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "0UZgY2KWkt93",
    "outputId": "95061b26-33ec-4784-df72-3c2c76287716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(wordvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9dUPwEfmFbWz",
    "outputId": "41f912c0-4667-4613-c91e-8c96af6cbabe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087235452866815"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(X, y)\n",
    "#prediction= rf.predict_proba(wordvec_df_test)\n",
    "prediction_class = rf.predict(wordvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "LEWlzS-nlAwi",
    "outputId": "a472652d-818c-4fe4-d551-90b5a956517f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.61      0.38      0.47     23367\n",
      "           e       0.47      0.87      0.61     30300\n",
      "           m       0.55      0.27      0.36      9207\n",
      "           t       0.55      0.25      0.34     21610\n",
      "\n",
      "    accuracy                           0.51     84484\n",
      "   macro avg       0.55      0.44      0.45     84484\n",
      "weighted avg       0.54      0.51      0.48     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pcw9zWdoFbW2"
   },
   "source": [
    "##### RF with doc2vec Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "61QaboqwlF1e",
    "outputId": "ea7cebc1-e8f8-47d4-feea-16aecaffb91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=docvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(docvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5NCuclqkFbW3",
    "outputId": "8352ee2e-b68b-476a-9f44-7f20671fd2c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3488826286634156"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(X, y)\n",
    "prediction_class = rf.predict(docvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "vFt40Ym6lSKM",
    "outputId": "68b0d0be-5761-429d-9749-4522fe35976f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.27      0.03      0.06     23367\n",
      "           e       0.36      0.92      0.52     30300\n",
      "           m       0.11      0.01      0.02      9207\n",
      "           t       0.26      0.03      0.06     21610\n",
      "\n",
      "    accuracy                           0.35     84484\n",
      "   macro avg       0.25      0.25      0.16     84484\n",
      "weighted avg       0.28      0.35      0.22     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvk7yT46FbW4"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "- bow = 57%\n",
    "- tfidf = 56%\n",
    "- word2vec = 57%\n",
    "- doc2vec = 41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tKP8YG3FbW4"
   },
   "source": [
    "# 4.4.XGBoost\n",
    "Extreme Gradient Boosting (xgboost) is an advanced implementation of gradient boosting algorithm. It has both linear model solver and tree learning algorithms. Its ability to do parallel computation on a single machine makes it extremely fast. It also has additional features for doing cross validation and finding important variables. There are many parameters which need to be controlled to optimize the model.\n",
    "\n",
    "Some key benefits of XGBoost are:\n",
    "\n",
    "Regularization - helps in reducing overfitting\n",
    "Parallel Processing - XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "Handling Missing Values - It has an in-built routine to handle missing values.\n",
    "Built-in Cross-Validation - allows user to run a cross-validation at each iteration of the boosting process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16EKMob3FbW5"
   },
   "source": [
    "**Notice there is no sklearn ready made model therefore; I needed to use XGBoost from its main librrary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWqxV7jDFbW5"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YjsO2nTFbW7"
   },
   "source": [
    "##### XGBoost using bag of words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "7BDoP1LIlU30",
    "outputId": "85bba548-3f2d-43ed-c8a3-08d6b6168d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=bow\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bow_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6h2H3WvzFbW7",
    "outputId": "14a875e4-d3e6-4654-dfc3-8fe14e64c5d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35864779129776053"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(X, y)\n",
    "prediction = xgb_model.predict_proba(bow_test)\n",
    "prediction_class = xgb_model.predict(bow_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "DI1Vy9S_ljQF",
    "outputId": "654356aa-b06c-480b-b836-a051e7e07646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.00      0.00      0.00     23367\n",
      "           e       0.36      1.00      0.53     30300\n",
      "           m       0.00      0.00      0.00      9207\n",
      "           t       0.00      0.00      0.00     21610\n",
      "\n",
      "    accuracy                           0.36     84484\n",
      "   macro avg       0.09      0.25      0.13     84484\n",
      "weighted avg       0.13      0.36      0.19     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_ibf9EJFbW9"
   },
   "source": [
    "##### XGBoost using tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "MoqAE8ItlnCi",
    "outputId": "969fe826-c3eb-4889-ded4-8cf61064e174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MpVDlVSEFbW9",
    "outputId": "3415d097-b2a8-49e7-e846-222940ba46a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2557880782159936"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(X, y)\n",
    "prediction = xgb_model.predict_proba(tfidf_test)\n",
    "prediction_class = xgb_model.predict(tfidf_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "atZ4CrqAl1r6",
    "outputId": "20b28067-3923-4dae-f215-e1672c9d0e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.00      0.00      0.00     23367\n",
      "           e       0.00      0.00      0.00     30300\n",
      "           m       0.00      0.00      0.00      9207\n",
      "           t       0.26      1.00      0.41     21610\n",
      "\n",
      "    accuracy                           0.26     84484\n",
      "   macro avg       0.06      0.25      0.10     84484\n",
      "weighted avg       0.07      0.26      0.10     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ipUywHkFbXA"
   },
   "source": [
    "##### XGBoost using word2vecfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "lvyOx7B_l4g0",
    "outputId": "efd461cc-ae50-4ae2-aef0-be9ce782f907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(wordvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ifRSbsHzFbXA",
    "outputId": "3ccaea4d-fffe-481f-843b-30b364b53942"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43125325505421147"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(X, y)\n",
    "prediction_class = xgb_model.predict(wordvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "0rlFVOavmD-I",
    "outputId": "7781a282-525c-4b1f-f0da-61f872076f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.61      0.39      0.48     23367\n",
      "           e       0.60      0.33      0.43     30300\n",
      "           m       0.51      0.32      0.40      9207\n",
      "           t       0.30      0.66      0.41     21610\n",
      "\n",
      "    accuracy                           0.43     84484\n",
      "   macro avg       0.51      0.43      0.43     84484\n",
      "weighted avg       0.52      0.43      0.44     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQHzF28HFbXC"
   },
   "source": [
    "##### XGBoost using doc2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "-LvPbYfHmMyX",
    "outputId": "42dd3aba-f7a9-43af-e2f4-bb5bb2ea8565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=docvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(docvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZucuGahBFbXD",
    "outputId": "07b7ed39-aef6-4764-acbf-8f811781d2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3488826286634156"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(X, y)\n",
    "prediction_class = xgb_model.predict(docvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "xWoKtwWgmXVH",
    "outputId": "46612213-729f-47aa-e29f-a01514224ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.27      0.03      0.06     23367\n",
      "           e       0.36      0.92      0.52     30300\n",
      "           m       0.11      0.01      0.02      9207\n",
      "           t       0.26      0.03      0.06     21610\n",
      "\n",
      "    accuracy                           0.35     84484\n",
      "   macro avg       0.25      0.25      0.16     84484\n",
      "weighted avg       0.28      0.35      0.22     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICbRc5T6FbXF"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "- bow = 54%\n",
    "- tfidf = 55%\n",
    "- word2vec = 58%\n",
    "- doc2vec = 37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26F5gNOVFbXF"
   },
   "source": [
    "### 4.5.MLPClassifier\n",
    "\n",
    "A multilayer perceptron (MLP) is a class of feedforward artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8V451n06FbXF"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30cm6SwJFbXH"
   },
   "source": [
    "##### MLP using bag of words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "2civSJSVoWCp",
    "outputId": "ed9cbdd6-99f7-45e2-b5ed-19abef0ca247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=bow\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bow_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lS4_uEoYFbXI",
    "outputId": "4e7999f6-af04-4dc7-eb9b-be1c07ec15d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599356091094172"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state=1, max_iter=300,learning_rate_init=0.001).fit(X, y)\n",
    "prediction = mlp_model.predict_proba(bow_test)\n",
    "prediction_class = mlp_model.predict(bow_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "PmDze9ilqSak",
    "outputId": "ca3952d4-3c09-4a26-c6b4-600c307c0a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.69      0.59      0.64     23367\n",
      "           e       0.68      0.81      0.74     30300\n",
      "           m       0.49      0.53      0.51      9207\n",
      "           t       0.68      0.58      0.63     21610\n",
      "\n",
      "    accuracy                           0.66     84484\n",
      "   macro avg       0.63      0.63      0.63     84484\n",
      "weighted avg       0.66      0.66      0.66     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxnfX4seFbXK"
   },
   "source": [
    "##### MLP using tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "deXvnYtfqUSC",
    "outputId": "48624a47-f646-442b-bf30-5959b5a1036d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(10000,)\n",
      "(84484, 1000)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(tfidf_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ySBkf5YeFbXK",
    "outputId": "ba561eab-36f4-4487-bf7c-c6d89996a171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6671085649353724"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state=1, max_iter=300,learning_rate_init=0.001).fit(X, y)\n",
    "prediction_class = mlp_model.predict(tfidf_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "jTtjwTs8uk1g",
    "outputId": "eb9cec0d-4c51-4c23-cc9e-ada2d9af225d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.69      0.61      0.65     23367\n",
      "           e       0.67      0.83      0.74     30300\n",
      "           m       0.57      0.49      0.53      9207\n",
      "           t       0.68      0.57      0.62     21610\n",
      "\n",
      "    accuracy                           0.67     84484\n",
      "   macro avg       0.65      0.63      0.63     84484\n",
      "weighted avg       0.67      0.67      0.66     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "az1Jci6bFbXN"
   },
   "source": [
    "##### MLP using word2vecfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "muqwRnL8unzJ",
    "outputId": "78876f0f-88d0-4a73-ea49-6e3df4b09ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000,)\n",
      "(84484, 200)\n",
      "(84484, 1)\n"
     ]
    }
   ],
   "source": [
    "X=wordvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(wordvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jnICqUl0FbXN",
    "outputId": "128bfe2d-e3da-4ba1-c7b4-160958565e54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4867548884995976"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state=1, max_iter=300,learning_rate_init=0.001).fit(X, y)\n",
    "prediction_class = mlp_model.predict(wordvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "kFIu4FCuvZZF",
    "outputId": "15467883-de4e-418e-faaf-106da368b468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.53      0.39      0.45     23367\n",
      "           e       0.47      0.81      0.59     30300\n",
      "           m       0.44      0.32      0.37      9207\n",
      "           t       0.55      0.21      0.30     21610\n",
      "\n",
      "    accuracy                           0.49     84484\n",
      "   macro avg       0.50      0.43      0.43     84484\n",
      "weighted avg       0.50      0.49      0.45     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQVsiDu7FbXP"
   },
   "source": [
    "##### MLP using doc2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4lkPqr9vGUb"
   },
   "outputs": [],
   "source": [
    "X=docvec_df\n",
    "y=data['category']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(docvec_df_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eufGRspKFbXP",
    "outputId": "4e81ce28-71fb-4c06-a8ef-6bd74cb5fc18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state=1, max_iter=300,learning_rate_init=0.001).fit(X, y)\n",
    "prediction_class = mlp_model.predict(docvec_df_test)\n",
    "accuracy_score(label_test, prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "MmTUrhUivciN",
    "outputId": "14402864-d07a-4401-de9e-5c79115480e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           b       0.53      0.39      0.45     23367\n",
      "           e       0.47      0.81      0.59     30300\n",
      "           m       0.44      0.32      0.37      9207\n",
      "           t       0.55      0.21      0.30     21610\n",
      "\n",
      "    accuracy                           0.49     84484\n",
      "   macro avg       0.50      0.43      0.43     84484\n",
      "weighted avg       0.50      0.49      0.45     84484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(label_test, prediction_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRxshQqqFbXQ"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "- bow = 65%\n",
    "- tfidf = 66%\n",
    "- word2vec = 48%\n",
    "- doc2vec = 41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ioVLZ3HFbXd"
   },
   "source": [
    "# END OF NOTEBOOK CODE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.Advanced_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
